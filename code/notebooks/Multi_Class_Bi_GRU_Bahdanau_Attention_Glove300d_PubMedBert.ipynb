{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRflG5kTQU07"
      },
      "source": [
        "---\n",
        "# Classification of Biomedical Texts with Deep Learning: LSTM, GRU, and Self-Attention\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahp61AK4QVvg"
      },
      "source": [
        "In this section, we leverage PubMedBERT to generate contextualized embeddings and GloVe (300-dimensional) for static word representations. We further integrate a Bahdanau attention mechanism within a bidirectional GRU-based architecture to enhance the modelâ€™s ability to focus on relevant textual features."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install biopython\n",
        "!pip install wandb -qU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgcY6Hg22DYN",
        "outputId": "e605ccca-446a-4e93-ddbd-789215a32195"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: biopython in /usr/local/lib/python3.11/dist-packages (1.85)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Bpjju4a10Tj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import pickle\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from collections import Counter\n",
        "import os\n",
        "import time\n",
        "import re\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import wandb\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_score\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from collections import Counter\n",
        "import torch.optim as optim\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data.dataset import ConcatDataset\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics import f1_score, confusion_matrix, balanced_accuracy_score, precision_score, recall_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tR2Sx5zd10Tk"
      },
      "outputs": [],
      "source": [
        "# To ensure reproducibility of the results\n",
        "SEED = 200\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fziWqTSj10Tk"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dg7lGdZp10Tl"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/diseases_dataset.csv')\n",
        "\n",
        "print(data.info())\n",
        "print()\n",
        "\n",
        "data[\"Label\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CvHB3JH10Tl"
      },
      "outputs": [],
      "source": [
        "print(data.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WK2x2H7410Tl"
      },
      "outputs": [],
      "source": [
        "data.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0s6JdzH10Tl"
      },
      "outputs": [],
      "source": [
        "X = data[\"Cleaned_Abstract\"].values\n",
        "y = data[\"Label\"].values\n",
        "\n",
        "# Split into training (70%), validation (15%), and test (15%) sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Training set: {len(X_train)} samples\")\n",
        "print(f\"Validation set: {len(X_val)} samples\")\n",
        "print(f\"Test set: {len(X_test)} samples\")\n",
        "\n",
        "NUM_CLASSES = len(set(y))\n",
        "print(NUM_CLASSES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aCVrTfr10Tm"
      },
      "outputs": [],
      "source": [
        "print(\"Training set class distribution:\", Counter(y_train))\n",
        "print(\"Validation set class distribution:\", Counter(y_val))\n",
        "print(\"Test set class distribution:\", Counter(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXQLbPNFUMOi"
      },
      "source": [
        "---\n",
        "Bahdanau attention mechanism within a bidirectional GRU-based architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFLtTO2y10Tm"
      },
      "outputs": [],
      "source": [
        "# --- PubMedBERT Setup ---\n",
        "pubmedbert_model_name = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(pubmedbert_model_name)\n",
        "pubmedbert = AutoModel.from_pretrained(pubmedbert_model_name).to(device)\n",
        "\n",
        "for param in pubmedbert.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwjlX2AP10Tm"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Bahdanau Attention Mechanism.\n",
        "\n",
        "    This class implements the Bahdanau attention mechanism as described in the paper:\n",
        "    \"Neural Machine Translation by Jointly Learning to Align and Translate\" by Bahdanau et al.\n",
        "\n",
        "    Args:\n",
        "        hidden_dim (int): The hidden dimension of the GRU or LSTM output.\n",
        "\n",
        "    Attributes:\n",
        "        W (nn.Linear): A linear layer for the transformation of the RNN outputs.\n",
        "        v (nn.Linear): A linear layer for computing attention scores.\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        self.v = nn.Linear(hidden_dim, 1, bias=False)\n",
        "\n",
        "    def forward(self, rnn_outputs):\n",
        "        \"\"\"\n",
        "        Apply the attention mechanism on the RNN outputs.\n",
        "\n",
        "        Args:\n",
        "            rnn_outputs (Tensor): The outputs of the RNN (GRU or LSTM).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: The context vector computed by the attention mechanism.\n",
        "        \"\"\"\n",
        "        score = torch.tanh(self.W(rnn_outputs))\n",
        "        attn_weights = torch.softmax(self.v(score), dim=1)\n",
        "        context = torch.sum(attn_weights * rnn_outputs, dim=1)\n",
        "        return context\n",
        "\n",
        "class PubMedBERT_GRU_Attention(nn.Module):\n",
        "    \"\"\"\n",
        "    Model combining PubMedBERT embeddings, GRU layers, and Bahdanau Attention mechanism for multi-class classification.\n",
        "\n",
        "    Args:\n",
        "        bert_dim (int): The dimension of the PubMedBERT embeddings (usually 768).\n",
        "        hidden_dim (int): The hidden dimension of the GRU layer.\n",
        "        num_classes (int): The number of output classes for classification (default is 9 for multi-class classification).\n",
        "        num_layers (int): The number of layers in the GRU (default is 1).\n",
        "        dropout_prob (float): Dropout probability for regularization.\n",
        "\n",
        "    Attributes:\n",
        "        gru (nn.GRU): A bidirectional GRU layer.\n",
        "        attention (BahdanauAttention): The Bahdanau attention mechanism.\n",
        "        fc (nn.Linear): The fully connected layer to produce the output predictions.\n",
        "        dropout (nn.Dropout): Dropout layer for regularization.\n",
        "    \"\"\"\n",
        "    def __init__(self, bert_dim, hidden_dim, num_classes=9, num_layers=1, dropout_prob=0.6):\n",
        "        super(PubMedBERT_GRU_Attention, self).__init__()\n",
        "\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=bert_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "\n",
        "        self.attention = BahdanauAttention(hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Forward pass of the model.\n",
        "\n",
        "        Args:\n",
        "            input_ids (Tensor): The tokenized input sequence IDs.\n",
        "            attention_mask (Tensor): The attention mask to differentiate padding from real tokens.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: The output logits for classification.\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            bert_outputs = pubmedbert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        bert_embeds = bert_outputs.last_hidden_state\n",
        "        gru_out, _ = self.gru(bert_embeds)\n",
        "        context = self.attention(gru_out)\n",
        "        x = self.dropout(context)\n",
        "        output = self.fc(x)  # Logits for multi-class classification\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmdOgOXD10Tm"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    \"\"\"\n",
        "    Count the number of trainable parameters in the model.\n",
        "    Args:\n",
        "        model: The model whose parameters are to be counted.\n",
        "    Returns:\n",
        "        Total number of trainable parameters.\n",
        "    \"\"\"\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def train_model(model, dataloader, optimizer, criterion, device):\n",
        "    \"\"\"\n",
        "    Train the model for one epoch, calculating loss and accuracy.\n",
        "    Args:\n",
        "        model: The model to train.\n",
        "        dataloader: DataLoader for the training dataset.\n",
        "        optimizer: Optimizer for model parameters.\n",
        "        criterion: Loss function.\n",
        "        device: CPU/GPU device.\n",
        "    Returns:\n",
        "        Average loss and accuracy for the epoch.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(input_ids, attention_mask)\n",
        "\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        preds = torch.argmax(logits, dim=1).cpu().detach().numpy()\n",
        "        total_correct += np.sum(preds == labels.cpu().numpy())\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    avg_accuracy = total_correct / total_samples\n",
        "    return avg_loss, avg_accuracy\n",
        "\n",
        "def evaluate_model(model, dataloader, criterion, device):\n",
        "    \"\"\"\n",
        "    Validate the model for one epoch, including precision, F1, balanced accuracy, and recall.\n",
        "    Args:\n",
        "        model: Model instance.\n",
        "        dataloader: DataLoader for validation data.\n",
        "        criterion: Loss function (CrossEntropyLoss).\n",
        "        device: CPU/GPU.\n",
        "    Returns:\n",
        "        Average validation loss, accuracy, F1-score.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    val_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            loss = criterion(logits, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "            labels_cpu = labels.cpu().numpy()\n",
        "\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels_cpu)\n",
        "\n",
        "    val_loss /= len(dataloader)\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
        "\n",
        "    return acc, f1, val_loss\n",
        "\n",
        "def test_model(model, test_loader, criterion, device):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the test dataset, calculating loss, accuracy, F1-score, precision, recall, and balanced accuracy.\n",
        "    Args:\n",
        "        model: The model to evaluate.\n",
        "        test_loader: DataLoader for the test dataset.\n",
        "        criterion: Loss function (CrossEntropyLoss).\n",
        "        device: CPU/GPU device.\n",
        "    Returns:\n",
        "        Average test loss, accuracy, F1-score, balanced accuracy, recall, and precision.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_accuracy = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            target_tensor = batch['labels'].to(device)\n",
        "\n",
        "            output = model(input_ids, attention_mask)\n",
        "            loss = criterion(output, target_tensor)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            batch_accuracy = accuracy_score(target_tensor.cpu(), torch.argmax(output, dim=1).cpu())\n",
        "            total_accuracy += batch_accuracy * len(target_tensor)\n",
        "\n",
        "            preds = torch.argmax(output, dim=1).cpu().numpy()\n",
        "            labels = target_tensor.cpu().numpy()\n",
        "\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels)\n",
        "\n",
        "    avg_loss = total_loss / len(test_loader)\n",
        "    avg_accuracy = total_accuracy / len(test_loader.dataset)\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    f1 = f1_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
        "\n",
        "    return avg_loss, avg_accuracy, f1, balanced_acc, recall, precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_1Zy9OR10Tn"
      },
      "outputs": [],
      "source": [
        "BERT_DIM = 768\n",
        "HIDDEN_DIM = 256\n",
        "DROPOUT = 0.6\n",
        "\n",
        "model = PubMedBERT_GRU_Attention(BERT_DIM, HIDDEN_DIM, dropout_prob=DROPOUT).to(device)\n",
        "print()\n",
        "print(f\"{count_parameters(model)} model parameters\")\n",
        "print()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68TA-KMERPVd"
      },
      "source": [
        "---\n",
        "\n",
        "#1. Use of PubMedBERT as contextual embeddings\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3nD7JK8aGs9"
      },
      "source": [
        "PubMedBERT is a model pre-trained on a corpus of biomedical texts, and generates contextual embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGgj_Hl510Tn"
      },
      "outputs": [],
      "source": [
        "class PubMedBERTBinaryDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset class for multi-class classification using PubMedBERT embeddings.\n",
        "\n",
        "    Args:\n",
        "        texts (list of str): A list of raw text sequences.\n",
        "        labels (list of int): A list of integer labels (0-8) corresponding to each text.\n",
        "        tokenizer (transformers tokenizer): A tokenizer to preprocess the text data.\n",
        "        max_length (int): Maximum length for padding/truncation. Default is 400.\n",
        "\n",
        "    Attributes:\n",
        "        texts (list of str): The raw text data.\n",
        "        encodings (dict): Tokenized text data with input IDs and attention masks.\n",
        "        labels (Tensor): Tensor of integer labels for the classification task.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=400):\n",
        "        self.texts = texts\n",
        "        self.encodings = tokenizer(texts, padding='max_length', truncation=True, max_length=max_length, return_tensors='pt')\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Retrieve a single sample from the dataset.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of the sample to retrieve.\n",
        "\n",
        "        Returns:\n",
        "            dict: Contains input IDs, attention masks, and the corresponding label and raw text.\n",
        "        \"\"\"\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        item['text'] = self.texts[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the total number of samples in the dataset.\n",
        "\n",
        "        Returns:\n",
        "            int: Number of samples in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ws7x-j-10Tn"
      },
      "outputs": [],
      "source": [
        "# --- Load Data ---\n",
        "train_dataset = PubMedBERTBinaryDataset(X_train.tolist(), y_train, tokenizer)\n",
        "val_dataset = PubMedBERTBinaryDataset(X_val.tolist(), y_val, tokenizer)\n",
        "test_dataset = PubMedBERTBinaryDataset(X_test.tolist(), y_test, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Combine the training and validation datasets (for test)\n",
        "combined_dataset = ConcatDataset([train_dataset, val_dataset])\n",
        "combined_loader = DataLoader(combined_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jl5kcmIQwPMK"
      },
      "source": [
        "---\n",
        "## 1.1 Optimisation phase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFWELZvRScpr"
      },
      "source": [
        "1.1.1 Optimizer selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnBF8LLY10Tn"
      },
      "outputs": [],
      "source": [
        "num_epochs = 5\n",
        "learning_rate = 1e-4\n",
        "weight_decay = 1e-3\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "optimizers = {\n",
        "    'Adam': optim.Adam,\n",
        "    'AdamW': optim.AdamW,\n",
        "    'RMSprop': optim.RMSprop,\n",
        "}\n",
        "\n",
        "all_train_losses = {}\n",
        "all_val_losses = {}\n",
        "all_train_accs = {}\n",
        "all_val_accs = {}\n",
        "\n",
        "for optimizer_name, optimizer_class in optimizers.items():\n",
        "    print(f\"\\nðŸ”¹ Training with optimizer: {optimizer_name}\")\n",
        "\n",
        "    model = PubMedBERT_GRU_Attention(BERT_DIM, HIDDEN_DIM, dropout_prob=DROPOUT).to(device)\n",
        "    print(model)\n",
        "\n",
        "    optimizer = optimizer_class(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
        "\n",
        "    wandb.init(project='Multi_Class_Pubmedbert_Attention_OptimizerSearch', name=f\"{optimizer_name}_run\", config={\n",
        "        'learning_rate': learning_rate,\n",
        "        'num_epochs': num_epochs,\n",
        "        'optimizer': optimizer_name,\n",
        "        'model': 'PubMedBERT_Bi_GRU_Bahdanau_Attention',\n",
        "        'hidden_dim': HIDDEN_DIM,\n",
        "        'dropout_prob': DROPOUT\n",
        "    })\n",
        "\n",
        "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Total trainable parameters: {num_params}\")\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accs, val_accs = [], []\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss, train_acc = train_model(model, train_loader, optimizer, criterion, device)\n",
        "        train_losses.append(train_loss)\n",
        "        train_accs.append(train_acc)\n",
        "\n",
        "        val_acc, f1, val_loss = evaluate_model(model, val_loader, criterion, device)\n",
        "        val_accs.append(val_acc)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        end_time = time.time()\n",
        "        duration = end_time - start_time\n",
        "\n",
        "        print(\n",
        "            f\"Opt: {optimizer_name} | Epoch {epoch+1}/{num_epochs} - \"\n",
        "            f\"TL: {train_loss:.4f}, VL: {val_loss:.4f}, \"\n",
        "            f\"TA: {train_acc:.2%}, VA: {val_acc:.2%}, F1: {f1:.2%}, \"\n",
        "            f\"Time: {duration/60:.2f} min\"\n",
        "        )\n",
        "\n",
        "        wandb.log({\n",
        "            'train_loss': train_loss,\n",
        "            'val_loss': val_loss,\n",
        "            'train_acc': train_acc,\n",
        "            'val_acc': val_acc,\n",
        "            'val_f1': f1,\n",
        "        })\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "    all_train_losses[optimizer_name] = train_losses\n",
        "    all_val_losses[optimizer_name] = val_losses\n",
        "    all_train_accs[optimizer_name] = train_accs\n",
        "    all_val_accs[optimizer_name] = val_accs\n",
        "\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpFLedQ5UqQb"
      },
      "source": [
        "---\n",
        "Adam optimizer is selected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4XISJ0FSzKy"
      },
      "source": [
        "1.1.2 Depth value selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dziUNoG410To"
      },
      "outputs": [],
      "source": [
        "depth_values = [1, 2, 3]\n",
        "num_epochs = 5\n",
        "learning_rate = 1e-4\n",
        "weight_decay = 1e-3\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "all_train_losses = {}\n",
        "all_val_losses = {}\n",
        "all_train_accs = {}\n",
        "all_val_accs = {}\n",
        "\n",
        "for depth in depth_values:\n",
        "    print(f\"\\nðŸ”¹ Training with GRU depth: {depth}\")\n",
        "\n",
        "    model = PubMedBERT_GRU_Attention(\n",
        "        bert_dim=BERT_DIM,\n",
        "        hidden_dim=HIDDEN_DIM,\n",
        "        num_classes=9,\n",
        "        num_layers=depth,\n",
        "        dropout_prob=DROPOUT\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
        "\n",
        "    wandb.init(\n",
        "        project='Multi_Class_Pubmedbert_Attention_DepthSearch',\n",
        "        name=f\"Depth_{depth}_run\",\n",
        "        config={\n",
        "            'learning_rate': learning_rate,\n",
        "            'num_epochs': num_epochs,\n",
        "            'optimizer': 'Adam',\n",
        "            'gru_depth': depth,\n",
        "            'model': 'PubMedBERT_Bi_GRU_Bahdanau_Attention',\n",
        "            'hidden_dim': HIDDEN_DIM,\n",
        "            'dropout_prob': DROPOUT\n",
        "        }\n",
        "    )\n",
        "\n",
        "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Total trainable parameters (depth={depth}): {num_params}\")\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accs, val_accs = [], []\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss, train_acc = train_model(model, train_loader, optimizer, criterion, device)\n",
        "        val_acc, f1, val_loss = evaluate_model(model, val_loader, criterion, device)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accs.append(val_acc)\n",
        "\n",
        "        end_time = time.time()\n",
        "        duration = end_time - start_time\n",
        "\n",
        "        print(\n",
        "            f\"Depth: {depth} | Epoch {epoch+1}/{num_epochs} - \"\n",
        "            f\"TL: {train_loss:.4f}, VL: {val_loss:.4f}, \"\n",
        "            f\"TA: {train_acc:.2%}, VA: {val_acc:.2%}, F1: {f1:.2%}, \"\n",
        "            f\"Time: {duration/60:.2f} min\"\n",
        "        )\n",
        "\n",
        "        wandb.log({\n",
        "            'train_loss': train_loss,\n",
        "            'val_loss': val_loss,\n",
        "            'train_acc': train_acc,\n",
        "            'val_acc': val_acc,\n",
        "            'val_f1': f1,\n",
        "        })\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "    all_train_losses[f'depth_{depth}'] = train_losses\n",
        "    all_val_losses[f'depth_{depth}'] = val_losses\n",
        "    all_train_accs[f'depth_{depth}'] = train_accs\n",
        "    all_val_accs[f'depth_{depth}'] = val_accs\n",
        "\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LsUzi6wUv5m"
      },
      "source": [
        "---\n",
        "Depth value is set to 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-MZh2WJ9g8B"
      },
      "source": [
        "1.3 Leanring rate value selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36ZrLdMn10To"
      },
      "outputs": [],
      "source": [
        "learning_rates = [9e-5, 7e-5, 5e-5]\n",
        "num_epochs = 5\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "all_train_losses = {}\n",
        "all_val_losses = {}\n",
        "all_train_accs = {}\n",
        "all_val_accs = {}\n",
        "\n",
        "for lr in learning_rates:\n",
        "    print(f\"\\nðŸ”¹ Training with learning rate: {lr}\")\n",
        "\n",
        "    model = PubMedBERT_GRU_Attention(\n",
        "        bert_dim=BERT_DIM,\n",
        "        hidden_dim=HIDDEN_DIM,\n",
        "        num_classes=9,\n",
        "        num_layers=2,\n",
        "        dropout_prob=DROPOUT\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-3)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
        "\n",
        "    wandb.init(\n",
        "        project='Multi_Class_Pubmedbert_Attention_LRTuning',\n",
        "        name=f\"LR_{lr}_run\",\n",
        "        config={\n",
        "            'learning_rate': lr,\n",
        "            'num_epochs': num_epochs,\n",
        "            'optimizer': 'Adam',\n",
        "            'gru_depth': depth,\n",
        "            'model': 'PubMedBERT_Bi_GRU_Bahdanau_Attention',\n",
        "            'hidden_dim': HIDDEN_DIM,\n",
        "            'dropout_prob': DROPOUT\n",
        "        }\n",
        "    )\n",
        "\n",
        "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Total trainable parameters (lr={lr}): {num_params}\")\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accs, val_accs = [], []\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss, train_acc = train_model(model, train_loader, optimizer, criterion, device)\n",
        "        val_acc, f1, val_loss = evaluate_model(model, val_loader, criterion, device)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accs.append(val_acc)\n",
        "\n",
        "        end_time = time.time()\n",
        "        duration = end_time - start_time\n",
        "\n",
        "        print(\n",
        "            f\"LR: {lr} | Epoch {epoch+1}/{num_epochs} - \"\n",
        "            f\"TL: {train_loss:.4f}, VL: {val_loss:.4f}, \"\n",
        "            f\"TA: {train_acc:.2%}, VA: {val_acc:.2%}, F1: {f1:.2%}, \"\n",
        "            f\"Time: {duration/60:.2f} min\"\n",
        "        )\n",
        "\n",
        "        wandb.log({\n",
        "            'train_loss': train_loss,\n",
        "            'val_loss': val_loss,\n",
        "            'train_acc': train_acc,\n",
        "            'val_acc': val_acc,\n",
        "            'val_f1': f1,\n",
        "        })\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "    all_train_losses[f'lr_{lr}'] = train_losses\n",
        "    all_val_losses[f'lr_{lr}'] = val_losses\n",
        "    all_train_accs[f'lr_{lr}'] = train_accs\n",
        "    all_val_accs[f'lr_{lr}'] = val_accs\n",
        "\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zLwAgfG9lJy"
      },
      "source": [
        "---\n",
        "Learning rate value is set to $ 9 \\cdot 10^{-5}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIQJyx-A4Pzs"
      },
      "source": [
        "---\n",
        "\n",
        "#2. Use of Glove (300d) as word embeddings\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lToyY6j4lt6"
      },
      "source": [
        "GloVe (Global Vectors for Word Representation) is a type of word embedding developed by the Stanford NLP Group."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWZZLmpr10Tp"
      },
      "outputs": [],
      "source": [
        "def tokenize(text):\n",
        "    \"\"\"\n",
        "    Tokenizes the input text by converting it to lowercase and splitting it into words.\n",
        "\n",
        "    Args:\n",
        "        text: A string containing the text to be tokenized.\n",
        "\n",
        "    Returns:\n",
        "        A list of tokens (words) from the text.\n",
        "    \"\"\"\n",
        "    return re.findall(r'\\b\\w+\\b', text.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ch2umO-z10Tp"
      },
      "outputs": [],
      "source": [
        "all_tokens = [token for text in X_train for token in tokenize(text)]\n",
        "vocab = Counter(all_tokens)\n",
        "filtered_vocab = {word: freq for word, freq in vocab.items() if freq >= 2}\n",
        "VOCAB_SIZE =  40000\n",
        "\n",
        "sorted_filtered_vocab = dict(sorted(filtered_vocab.items(), key=lambda item: item[1], reverse=True)[:VOCAB_SIZE])\n",
        "\n",
        "word_to_index = {word: idx for idx, (word, _) in enumerate(sorted_filtered_vocab.items(), 1)}\n",
        "word_to_index[\"<PAD>\"] = 0\n",
        "word_to_index[\"<UNK>\"] = len(word_to_index)\n",
        "\n",
        "index_to_word = {idx: word for word, idx in word_to_index.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GuCcNZu10Tp"
      },
      "outputs": [],
      "source": [
        "def text_to_sequence(text):\n",
        "    \"\"\"\n",
        "    Converts the tokenized text into a sequence of indices based on a word-to-index mapping.\n",
        "\n",
        "    Args:\n",
        "        text: A string containing the text to be converted.\n",
        "\n",
        "    Returns:\n",
        "        A list of integers representing the sequence of token indices.\n",
        "    \"\"\"\n",
        "    return [word_to_index.get(token, word_to_index[\"<UNK>\"]) for token in tokenize(text)]\n",
        "\n",
        "def pad_to_tensor(sequences, max_len=None):\n",
        "    \"\"\"\n",
        "    Pads sequences to the specified maximum length, or truncates them if they exceed it.\n",
        "\n",
        "    Args:\n",
        "        sequences: A list of sequences (each sequence is a list of integers).\n",
        "        max_len: The maximum length to which sequences should be padded. If None, no padding is applied.\n",
        "\n",
        "    Returns:\n",
        "        A tensor containing the padded (or truncated) sequences.\n",
        "    \"\"\"\n",
        "    padded_sequences = [torch.tensor(seq, dtype=torch.long) for seq in sequences]\n",
        "    if max_len:\n",
        "        padded_sequences = [seq[:max_len] for seq in padded_sequences]\n",
        "        padded_sequences = [\n",
        "            torch.cat([seq, torch.zeros(max_len - len(seq), dtype=torch.long)], 0) if len(seq) < max_len else seq\n",
        "            for seq in padded_sequences\n",
        "        ]\n",
        "\n",
        "    return torch.stack(padded_sequences)\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom Dataset for handling text data and labels.\n",
        "\n",
        "    Args:\n",
        "        X_data: Input features (e.g., tokenized text).\n",
        "        y_data: Labels corresponding to the text data.\n",
        "        raw_text_data: (Optional) The raw text data for reference (default is None).\n",
        "    \"\"\"\n",
        "    def __init__(self, X_data, y_data, raw_text_data=None):\n",
        "        self.X = torch.tensor(X_data, dtype=torch.long)\n",
        "        self.y = torch.tensor(y_data, dtype=torch.long)\n",
        "        self.raw_text_data = raw_text_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_tensor = self.X[idx]\n",
        "        target_tensor = self.y[idx]\n",
        "        raw_text = self.raw_text_data[idx] if self.raw_text_data is not None else None\n",
        "        return input_tensor, target_tensor, raw_text\n",
        "\n",
        "def load_glove_embeddings(glove_path, word_to_index, embedding_dim):\n",
        "    \"\"\"Loads GloVe embeddings and returns an embedding matrix.\"\"\"\n",
        "    embedding_matrix = np.zeros((len(word_to_index), embedding_dim), dtype='float32')\n",
        "    with open(glove_path, 'r', encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            values = line.strip().split()\n",
        "            word = values[0]\n",
        "            if word in word_to_index:\n",
        "                vector = np.asarray(values[1:], dtype='float32')\n",
        "                embedding_matrix[word_to_index[word]] = vector\n",
        "\n",
        "    return torch.tensor(embedding_matrix, dtype=torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IW8UAEfh10Tp"
      },
      "outputs": [],
      "source": [
        "X_train_seq = [text_to_sequence(text) for text in X_train]\n",
        "X_val_seq = [text_to_sequence(text) for text in X_val]\n",
        "X_test_seq = [text_to_sequence(text) for text in X_test]\n",
        "\n",
        "print(X_train_seq[0])\n",
        "max_length = 400\n",
        "\n",
        "X_train_tensor = pad_to_tensor(X_train_seq, max_len=max_length)\n",
        "X_val_tensor = pad_to_tensor(X_val_seq, max_len=max_length)\n",
        "X_test_tensor = pad_to_tensor(X_test_seq, max_len=max_length)\n",
        "\n",
        "print(f\"Train Tensor Shape: {X_train_tensor.shape}, Type: {X_train_tensor.dtype}\")\n",
        "print(f\"Validation Tensor Shape: {X_val_tensor.shape}, Type: {X_val_tensor.dtype}\")\n",
        "print(f\"Test Tensor Shape: {X_test_tensor.shape}, Type: {X_test_tensor.dtype}\")\n",
        "\n",
        "y_train_tensor = torch.tensor(y_train)\n",
        "y_val_tensor = torch.tensor(y_val)\n",
        "y_test_tensor = torch.tensor(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O00l4VuA10Tp"
      },
      "outputs": [],
      "source": [
        "class GloVe_GRU_BahdanauAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Model using GloVe embeddings, GRU layers, and Bahdanau Attention for classification.\n",
        "\n",
        "    Args:\n",
        "        embedding_matrix (Tensor): Pretrained GloVe embedding matrix.\n",
        "        hidden_dim (int): Hidden size for the GRU.\n",
        "        num_classes (int): Output classes.\n",
        "        num_layers (int): GRU depth.\n",
        "        dropout_prob (float): Dropout rate.\n",
        "    \"\"\"\n",
        "    def __init__(self, embedding_matrix, hidden_dim, num_classes=NUM_CLASSES, num_layers=1, dropout_prob=0.6):\n",
        "        super(GloVe_GRU_BahdanauAttention, self).__init__()\n",
        "\n",
        "        vocab_size, embedding_dim = embedding_matrix.shape\n",
        "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
        "\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "\n",
        "        self.attention = BahdanauAttention(hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x (Tensor): Tensor of token indices (batch_size, seq_len)\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Output logits for classification.\n",
        "        \"\"\"\n",
        "        embedded = self.embedding(x)\n",
        "        gru_out, _ = self.gru(embedded)\n",
        "        context = self.attention(gru_out)\n",
        "        x = self.dropout(context)\n",
        "        output = self.fc(x)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPyCKIEy10Tp"
      },
      "outputs": [],
      "source": [
        "def calculate_accuracy(y_pred, y_true):\n",
        "    \"\"\"\n",
        "    Compute classification accuracy for multi-class predictions.\n",
        "\n",
        "    Args:\n",
        "        y_pred (Tensor): Raw output logits from the model of shape (batch_size, num_classes).\n",
        "        y_true (Tensor): Ground truth labels of shape (batch_size,).\n",
        "\n",
        "    Returns:\n",
        "        float: Accuracy score over the batch.\n",
        "    \"\"\"\n",
        "    preds = torch.argmax(y_pred, dim=1)\n",
        "    correct = (preds == y_true).sum().item()\n",
        "    total = y_true.size(0)\n",
        "    return correct / total\n",
        "\n",
        "def train_epoch_glove(model, train_loader, optimizer, criterion, device):\n",
        "    \"\"\"\n",
        "    Train the model for one epoch on the training data using GloVe embeddings.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The model to be trained.\n",
        "        train_loader (DataLoader): DataLoader for the training data.\n",
        "        optimizer (torch.optim.Optimizer): Optimizer for training.\n",
        "        criterion (nn.Module): Loss function.\n",
        "        device (torch.device): Device to run the training on (CPU or CUDA).\n",
        "\n",
        "    Returns:\n",
        "        Tuple[float, float]: Average loss and accuracy over the epoch.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        if len(batch) == 3:\n",
        "            input_tensor, target_tensor, _ = batch  # Ignore raw_text\n",
        "        input_tensor, target_tensor = input_tensor.to(device), target_tensor.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(input_tensor)\n",
        "\n",
        "        loss = criterion(output, target_tensor)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        acc = calculate_accuracy(output, target_tensor)\n",
        "        total_loss += loss.item()\n",
        "        total_accuracy += acc * input_tensor.size(0)\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    avg_accuracy = total_accuracy / len(train_loader.dataset)\n",
        "\n",
        "    return avg_loss, avg_accuracy\n",
        "\n",
        "\n",
        "def validate_epoch_glove(model, val_loader, criterion, device):\n",
        "    \"\"\"\n",
        "    Validate the model on the validation set and compute weighted F1 and accuracy.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The trained model.\n",
        "        val_loader (DataLoader): DataLoader for the validation data.\n",
        "        criterion (nn.Module): Loss function.\n",
        "        device (torch.device): Device to run validation on.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[float, float, float]: Average loss, F1 score, and accuracy.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            if len(batch) == 3:\n",
        "                input_tensor, target_tensor, _ = batch  # Ignore raw_text\n",
        "            input_tensor, target_tensor = input_tensor.to(device), target_tensor.to(device)\n",
        "\n",
        "            output = model(input_tensor)  # logits\n",
        "\n",
        "            loss = criterion(output, target_tensor)\n",
        "            acc = calculate_accuracy(output, target_tensor)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_accuracy += acc * input_tensor.size(0)\n",
        "\n",
        "            preds = torch.argmax(output, dim=1).cpu().numpy()\n",
        "            labels = target_tensor.cpu().numpy()\n",
        "\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels)\n",
        "\n",
        "    avg_loss = total_loss / len(val_loader)\n",
        "    avg_accuracy = total_accuracy / len(val_loader.dataset)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "\n",
        "    return  avg_accuracy, f1, avg_loss\n",
        "\n",
        "def test_epoch_glove(model, val_loader, criterion, device):\n",
        "    \"\"\"\n",
        "    Validate the model and compute a complete set of metrics for multi-class classification.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The trained model.\n",
        "        val_loader (DataLoader): DataLoader for the validation data.\n",
        "        criterion (nn.Module): Loss function.\n",
        "        device (torch.device): Device to run validation on.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[float, float, float, float, float, float]:\n",
        "            Average loss, accuracy, F1 score (weighted),\n",
        "            balanced accuracy, recall (weighted), precision (weighted).\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            if len(batch) == 3:\n",
        "                input_tensor, target_tensor, _ = batch  # Ignore raw_text\n",
        "            else:\n",
        "                input_tensor, target_tensor = batch\n",
        "\n",
        "            input_tensor = input_tensor.to(device)\n",
        "            target_tensor = target_tensor.to(device).long()\n",
        "\n",
        "            output = model(input_tensor)  # logits\n",
        "\n",
        "            loss = criterion(output, target_tensor)\n",
        "            acc = calculate_accuracy(output, target_tensor)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_accuracy += acc * input_tensor.size(0)\n",
        "\n",
        "            preds = torch.argmax(output, dim=1).cpu().numpy()\n",
        "            labels = target_tensor.cpu().numpy()\n",
        "\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels)\n",
        "\n",
        "    avg_loss = total_loss / len(val_loader)\n",
        "    avg_accuracy = total_accuracy / len(val_loader.dataset)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "\n",
        "    return avg_loss, avg_accuracy, f1, balanced_acc, recall, precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70TKii6W10Tp"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_DIM = 300\n",
        "embedding_matrix = load_glove_embeddings('/content/drive/MyDrive/glove/glove.6B.300d.txt', word_to_index, EMBEDDING_DIM)\n",
        "\n",
        "train_dataset = TextDataset(X_train_tensor, y_train, raw_text_data=X_train)\n",
        "val_dataset = TextDataset(X_val_tensor, y_val, raw_text_data=X_val)\n",
        "test_dataset = TextDataset(X_test_tensor, y_test, raw_text_data=X_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDzA8dRB_ohq"
      },
      "source": [
        "---\n",
        "## 2.1 Optimisation phase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P52-z8td85HX"
      },
      "source": [
        "2.1.1 Optimizer selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQKRFnsn10Tq"
      },
      "outputs": [],
      "source": [
        "num_epochs = 7\n",
        "learning_rate = 7e-4\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "optimizers = {\n",
        "    'RMSprop': optim.RMSprop,\n",
        "    'Adam': optim.Adam,\n",
        "    'AdamW': optim.AdamW,\n",
        "}\n",
        "\n",
        "for optimizer_name, optimizer_class in optimizers.items():\n",
        "    print(f\"\\nðŸ”¹ Training with optimizer: {optimizer_name}\")\n",
        "\n",
        "    model = GloVe_GRU_BahdanauAttention(embedding_matrix=embedding_matrix, hidden_dim=350, num_layers=1, dropout_prob=0.8).to(device)\n",
        "    optimizer = optimizer_class(model.parameters(), lr=learning_rate)\n",
        "    wandb.init(project='Multi_Class_Optimizer_Comparison_gru_attention_glove300d', name=f\"{optimizer_name}_run\", config={\n",
        "        'learning_rate': learning_rate,\n",
        "        'num_epochs': num_epochs,\n",
        "        'optimizer': optimizer_name,\n",
        "        'model': 'GRU_Model',\n",
        "        'embedding_dim': 300,\n",
        "        'hidden_dim': 350,\n",
        "        'dropout_prob': 0.5\n",
        "    })\n",
        "\n",
        "    print(model)\n",
        "    num_params = count_parameters(model)\n",
        "    print(f\"Total trainable parameters: {num_params}\")\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accs, val_accs = [], []\n",
        "    val_f1s = []\n",
        "\n",
        "    with tqdm(total=num_epochs, desc=f\"Optimizer: {optimizer_name}\", unit=\"epoch\") as pbar:\n",
        "        for epoch in range(num_epochs):\n",
        "            start_time = time.time()\n",
        "\n",
        "            train_loss, train_acc = train_epoch_glove(model, train_loader, optimizer, loss_function, device)\n",
        "            train_losses.append(train_loss)\n",
        "            train_accs.append(train_acc)\n",
        "\n",
        "            val_acc, val_f1, val_loss = validate_epoch_glove(model, val_loader, loss_function, device)\n",
        "            val_losses.append(val_loss)\n",
        "            val_accs.append(val_acc)\n",
        "            val_f1s.append(val_f1)\n",
        "\n",
        "            end_time = time.time()\n",
        "            epoch_duration = end_time - start_time\n",
        "\n",
        "            pbar.set_description(f\"Optimizer: {optimizer_name} | Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Train ACC: {train_acc:.2%}, Val ACC: {val_acc:.2%}, Time: {epoch_duration / 60:.2f} min\")\n",
        "            pbar.update(1)\n",
        "\n",
        "            wandb.log({\n",
        "                'train_loss': train_loss,\n",
        "                'val_loss': val_loss,\n",
        "                'train_acc': train_acc,\n",
        "                'val_acc': val_acc,\n",
        "                'val_f1': val_f1,\n",
        "            })\n",
        "\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KspjcBde8mq4"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpJUMGkahvK_"
      },
      "source": [
        "RMSprop optimizer is selected as optimizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPknl839-nbg"
      },
      "source": [
        "2.1.2 Learning rate value selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6erhbraL10Tq"
      },
      "outputs": [],
      "source": [
        "learning_rates = [9e-5, 7e-5, 5e-5]\n",
        "optimizer_class = optim.RMSprop\n",
        "\n",
        "for lr in learning_rates:\n",
        "    optimizer_name = \"RMSprop\"\n",
        "    print(f\"\\nðŸ”¹ Training with optimizer: {optimizer_name} | Learning rate: {lr}\")\n",
        "\n",
        "    model = GloVe_GRU_BahdanauAttention(\n",
        "        embedding_matrix=embedding_matrix,\n",
        "        hidden_dim=300,\n",
        "        num_classes=NUM_CLASSES,\n",
        "        num_layers=1,\n",
        "        dropout_prob=0.9\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = optimizer_class(model.parameters(), lr=lr, weight_decay = 1e-5)\n",
        "\n",
        "    wandb.init(\n",
        "        project='Multi_Class_lr_Tuning_gru_attention_glove300d',\n",
        "        name=f\"{optimizer_name}_lr{lr}\",\n",
        "        config={\n",
        "            'learning_rate': lr,\n",
        "            'num_epochs': num_epochs,\n",
        "            'optimizer': optimizer_name,\n",
        "            'model': 'GRU_Model',\n",
        "            'embedding_dim': 300,\n",
        "            'hidden_dim': 350,\n",
        "            'dropout_prob': 0.8\n",
        "        }\n",
        "    )\n",
        "\n",
        "    print(model)\n",
        "    num_params = count_parameters(model)\n",
        "    print(f\"Total trainable parameters: {num_params}\")\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accs, val_accs = [], []\n",
        "    val_f1s = []\n",
        "\n",
        "    with tqdm(total=num_epochs, desc=f\"Optimizer: {optimizer_name} | LR: {lr}\", unit=\"epoch\") as pbar:\n",
        "        for epoch in range(num_epochs):\n",
        "            start_time = time.time()\n",
        "\n",
        "            train_loss, train_acc = train_epoch_glove(model, train_loader, optimizer, loss_function, device)\n",
        "            train_losses.append(train_loss)\n",
        "            train_accs.append(train_acc)\n",
        "\n",
        "            val_acc, val_f1, val_loss = validate_epoch_glove(model, val_loader, loss_function, device)\n",
        "            val_losses.append(val_loss)\n",
        "            val_accs.append(val_acc)\n",
        "            val_f1s.append(val_f1)\n",
        "\n",
        "            end_time = time.time()\n",
        "            epoch_duration = end_time - start_time\n",
        "\n",
        "            pbar.set_description(\n",
        "                f\"Optimizer: {optimizer_name} | LR: {lr} | Epoch {epoch+1}/{num_epochs} - \"\n",
        "                f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
        "                f\"Train ACC: {train_acc:.2%}, Val ACC: {val_acc:.2%}, \"\n",
        "                f\"F1: {val_f1:.2f}, Time: {epoch_duration / 60:.2f} min\"\n",
        "            )\n",
        "            pbar.update(1)\n",
        "\n",
        "            wandb.log({\n",
        "                'train_loss': train_loss,\n",
        "                'val_loss': val_loss,\n",
        "                'train_acc': train_acc,\n",
        "                'val_acc': val_acc,\n",
        "                'val_f1': val_f1,\n",
        "            })\n",
        "\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq4TMzv58oYf"
      },
      "source": [
        "---\n",
        "Learning rate value is set to $9 \\cdot 10{-5}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0czxKca-soV"
      },
      "source": [
        "2.1.3 Depth value selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMek1N0E10Tq"
      },
      "outputs": [],
      "source": [
        "learning_rate = 9e-5\n",
        "depth_values = [1, 2, 3]\n",
        "\n",
        "for depth in depth_values:\n",
        "    optimizer_name = \"RMSprop\"\n",
        "    print(f\"\\nðŸ”¹ Training with optimizer: {optimizer_name} | Depth: {depth}\")\n",
        "\n",
        "    model = GloVe_GRU_BahdanauAttention(\n",
        "        embedding_matrix=embedding_matrix,\n",
        "        hidden_dim=300,\n",
        "        num_classes=NUM_CLASSES,\n",
        "        num_layers=depth,\n",
        "        dropout_prob=0.9\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = optimizer_class(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    wandb.init(\n",
        "        project='Multi_Class_Depth_Tuning_gru_attention_glove300d',\n",
        "        name=f\"{optimizer_name}_depth{depth}\",\n",
        "        config={\n",
        "            'learning_rate': learning_rate,\n",
        "            'num_epochs': num_epochs,\n",
        "            'optimizer': optimizer_name,\n",
        "            'model': 'GRU_Model',\n",
        "            'embedding_dim': 300,\n",
        "            'hidden_dim': 300,\n",
        "            'dropout_prob': 0.9,\n",
        "            'num_layers': depth\n",
        "        }\n",
        "    )\n",
        "\n",
        "    print(model)\n",
        "    num_params = count_parameters(model)\n",
        "    print(f\"Total trainable parameters: {num_params}\")\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accs, val_accs = [], []\n",
        "    val_f1s = []\n",
        "\n",
        "    with tqdm(total=num_epochs, desc=f\"Optimizer: {optimizer_name} | Depth: {depth}\", unit=\"epoch\") as pbar:\n",
        "        for epoch in range(num_epochs):\n",
        "            start_time = time.time()\n",
        "\n",
        "            train_loss, train_acc = train_epoch_glove(model, train_loader, optimizer, loss_function, device)\n",
        "            train_losses.append(train_loss)\n",
        "            train_accs.append(train_acc)\n",
        "\n",
        "            val_acc, val_f1, val_loss = validate_epoch_glove(model, val_loader, loss_function, device)\n",
        "            val_losses.append(val_loss)\n",
        "            val_accs.append(val_acc)\n",
        "            val_f1s.append(val_f1)\n",
        "\n",
        "            end_time = time.time()\n",
        "            epoch_duration = end_time - start_time\n",
        "\n",
        "            pbar.set_description(\n",
        "                f\"Optimizer: {optimizer_name} | Depth: {depth} | Epoch {epoch+1}/{num_epochs} - \"\n",
        "                f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
        "                f\"Train ACC: {train_acc:.2%}, Val ACC: {val_acc:.2%}, \"\n",
        "                f\"F1: {val_f1:.2f}, Time: {epoch_duration / 60:.2f} min\"\n",
        "            )\n",
        "            pbar.update(1)\n",
        "\n",
        "            wandb.log({\n",
        "                'train_loss': train_loss,\n",
        "                'val_loss': val_loss,\n",
        "                'train_acc': train_acc,\n",
        "                'val_acc': val_acc,\n",
        "                'val_f1': val_f1,\n",
        "            })\n",
        "\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVaEVro7-xlA"
      },
      "source": [
        "---\n",
        "Depth value is set to 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaUEKiy_-zZH"
      },
      "source": [
        "2.1.4 Batch size value selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGte02ge10Tr"
      },
      "outputs": [],
      "source": [
        "num_epochs = 7\n",
        "learning_rate = 9e-5\n",
        "optimizer_class = optim.RMSprop\n",
        "batch_sizes = [8, 16, 32, 64]\n",
        "depth = 1\n",
        "\n",
        "for BATCH_SIZE in batch_sizes:\n",
        "    optimizer_name = \"RMSprop\"\n",
        "    print(f\"\\nðŸ”¹ Training with optimizer: {optimizer_name} | Batch Size: {BATCH_SIZE}\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    model = GloVe_GRU_BahdanauAttention(embedding_matrix=embedding_matrix, hidden_dim=300, num_classes=NUM_CLASSES, num_layers=depth, dropout_prob=0.9).to(device)\n",
        "    optimizer = optimizer_class(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    wandb.init(\n",
        "        project='Multi_Class_Batch_Tuning_gru_attention_glove300d',\n",
        "        name=f\"{optimizer_name}_batch{BATCH_SIZE}\",\n",
        "        config={\n",
        "            'learning_rate': learning_rate,\n",
        "            'num_epochs': num_epochs,\n",
        "            'optimizer': optimizer_name,\n",
        "            'model': 'GRU_Model',\n",
        "            'embedding_dim': 300,\n",
        "            'hidden_dim': 300,\n",
        "            'dropout_prob': 0.9,\n",
        "            'num_layers': depth,\n",
        "            'batch_size': BATCH_SIZE\n",
        "        }\n",
        "    )\n",
        "\n",
        "    print(model)\n",
        "    num_params = count_parameters(model)\n",
        "    print(f\"Total trainable parameters: {num_params}\")\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accs, val_accs = [], []\n",
        "    val_f1s = []\n",
        "\n",
        "    with tqdm(total=num_epochs, desc=f\"Optimizer: {optimizer_name} | Batch: {BATCH_SIZE}\", unit=\"epoch\") as pbar:\n",
        "        for epoch in range(num_epochs):\n",
        "            start_time = time.time()\n",
        "\n",
        "            train_loss, train_acc = train_epoch_glove(model, train_loader, optimizer, loss_function, device)\n",
        "            train_losses.append(train_loss)\n",
        "            train_accs.append(train_acc)\n",
        "\n",
        "            val_acc, val_f1, val_loss = validate_epoch_glove(model, val_loader, loss_function, device)\n",
        "            val_losses.append(val_loss)\n",
        "            val_accs.append(val_acc)\n",
        "            val_f1s.append(val_f1)\n",
        "\n",
        "            end_time = time.time()\n",
        "            epoch_duration = end_time - start_time\n",
        "\n",
        "            pbar.set_description(\n",
        "                f\"Optimizer: {optimizer_name} | Batch: {BATCH_SIZE} | Epoch {epoch+1}/{num_epochs} - \"\n",
        "                f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
        "                f\"Train ACC: {train_acc:.2%}, Val ACC: {val_acc:.2%}, \"\n",
        "                f\"F1: {val_f1:.2f}, Time: {epoch_duration / 60:.2f} min\"\n",
        "            )\n",
        "            pbar.update(1)\n",
        "\n",
        "            wandb.log({\n",
        "                'train_loss': train_loss,\n",
        "                'val_loss': val_loss,\n",
        "                'train_acc': train_acc,\n",
        "                'val_acc': val_acc,\n",
        "                'val_f1': val_f1,\n",
        "            })\n",
        "\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqAXN7mJC6aK"
      },
      "source": [
        "---\n",
        "Batch size value is set to 32."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVfMubKys_bD"
      },
      "source": [
        "---\n",
        "#3. Test phase\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgJjXWWR10Tr"
      },
      "outputs": [],
      "source": [
        "def reinitialize_weights(model):\n",
        "    \"\"\"Reinitializes the model's weights by calling reset_parameters() for each layer that supports it.\"\"\"\n",
        "    for layer in model.children():\n",
        "        if hasattr(layer, 'reset_parameters'):\n",
        "            layer.reset_parameters()\n",
        "\n",
        "def plot_confusion_matrix(ax, y_true, y_pred, num_classes):\n",
        "    \"\"\"Plots a confusion matrix as a heatmap.\n",
        "\n",
        "    Args:\n",
        "        ax (matplotlib.axes.Axes): The axes on which to plot the confusion matrix.\n",
        "        y_true (list or array): The true class labels for the test set.\n",
        "        y_pred (list or array): The predicted class labels for the test set.\n",
        "        num_classes (int): The number of unique classes in the dataset.\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=range(num_classes))\n",
        "    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=range(num_classes), yticklabels=range(num_classes), ax=ax)\n",
        "    ax.set_xlabel('Predicted')\n",
        "    ax.set_ylabel('True')\n",
        "    ax.set_title('Confusion Matrix')\n",
        "\n",
        "def evaluate_and_analyze_glove(model, test_loader, device):\n",
        "    \"\"\"Evaluates and analyzes model performance on the test set.\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    all_probs = []\n",
        "    all_indices = []\n",
        "\n",
        "    top_correct = []\n",
        "    top_wrong = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (inputs, labels, raw_text) in enumerate(test_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "            preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "            all_indices.extend(range(len(labels)))\n",
        "\n",
        "            correct_indices = (preds == labels).nonzero(as_tuple=True)[0]\n",
        "            wrong_indices = (preds != labels).nonzero(as_tuple=True)[0]\n",
        "\n",
        "            for correct_idx in correct_indices[:]:\n",
        "                top_correct.append({\n",
        "                    'index': correct_idx.item(),\n",
        "                    'true_label': labels[correct_idx].item(),\n",
        "                    'predicted_label': preds[correct_idx].item(),\n",
        "                    'probability': probs[correct_idx, preds[correct_idx]].cpu().item(),\n",
        "                    'text': raw_text[correct_idx.item()] if raw_text is not None else None\n",
        "                })\n",
        "\n",
        "            for wrong_idx in wrong_indices[:]:\n",
        "                top_wrong.append({\n",
        "                    'index': wrong_idx.item(),\n",
        "                    'true_label': labels[wrong_idx].item(),\n",
        "                    'predicted_label': preds[wrong_idx].item(),\n",
        "                    'probability': probs[wrong_idx, preds[wrong_idx]].cpu().item(),\n",
        "                    'text': raw_text[wrong_idx.item()] if raw_text is not None else None\n",
        "                })\n",
        "\n",
        "    df_correct = pd.DataFrame(top_correct)\n",
        "    df_wrong = pd.DataFrame(top_wrong)\n",
        "\n",
        "    class_report = classification_report(all_labels, all_preds, output_dict=True)\n",
        "    df_results = pd.DataFrame(class_report).transpose()\n",
        "\n",
        "    return df_results, df_correct, df_wrong, all_labels, all_preds\n",
        "\n",
        "def evaluate_and_analyze_pubMedBert(model, test_loader, device):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    all_probs = []\n",
        "    all_indices = []\n",
        "    all_texts = []\n",
        "\n",
        "    wrong_samples = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(test_loader):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            texts = batch['text']\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "            preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "            all_indices.extend(range(batch_idx * test_loader.batch_size, (batch_idx + 1) * test_loader.batch_size))\n",
        "            all_texts.extend(texts)\n",
        "\n",
        "            for idx, (pred, prob, label, text) in enumerate(zip(preds, probs, labels, texts)):\n",
        "                if pred != label:\n",
        "                    wrong_samples.append({\n",
        "                        \"index\": batch_idx * test_loader.batch_size + idx,\n",
        "                        \"true_label\": label.item(),\n",
        "                        \"predicted_label\": pred.item(),\n",
        "                        \"probability\": prob[pred].item(),\n",
        "                        \"text\": text\n",
        "                    })\n",
        "\n",
        "    class_stats = defaultdict(lambda: {'correct': 0, 'wrong': 0})\n",
        "    for true_label, pred_label in zip(all_labels, all_preds):\n",
        "        true_label = true_label.item()\n",
        "        pred_label = pred_label.item()\n",
        "        if true_label == pred_label:\n",
        "            class_stats[true_label]['correct'] += 1\n",
        "        else:\n",
        "            class_stats[true_label]['wrong'] += 1\n",
        "\n",
        "    class_results = []\n",
        "    for cls in sorted(class_stats.keys()):\n",
        "        total = class_stats[cls]['correct'] + class_stats[cls]['wrong']\n",
        "        success_rate = (class_stats[cls]['correct'] / total) * 100 if total > 0 else 0\n",
        "        failure_rate = (class_stats[cls]['wrong'] / total) * 100 if total > 0 else 0\n",
        "        class_results.append({'class': cls, 'success_rate': success_rate, 'failure_rate': failure_rate})\n",
        "\n",
        "    df_results = pd.DataFrame(class_results)\n",
        "\n",
        "    wrong_df = pd.DataFrame(wrong_samples)\n",
        "    top_8_wrong = wrong_df.sort_values(by='probability', ascending=False).head(8)\n",
        "\n",
        "    correct_samples = []\n",
        "    for idx, (pred, prob, label, text) in enumerate(zip(all_preds, all_probs, all_labels, all_texts)):\n",
        "        if pred == label:\n",
        "            correct_samples.append({\n",
        "                \"index\": idx,\n",
        "                \"true_label\": label.item(),\n",
        "                \"predicted_label\": pred.item(),\n",
        "                \"probability\": prob[pred].item(),\n",
        "                \"text\": text\n",
        "            })\n",
        "\n",
        "    correct_df = pd.DataFrame(correct_samples)\n",
        "    top_8_correct = correct_df.sort_values(by='probability', ascending=False).head(8)\n",
        "\n",
        "    return df_results, top_8_wrong, top_8_correct, all_labels, all_preds\n",
        "\n",
        "def plot_wrong_distributions(wrong_indices, all_labels, all_preds, num_classes = NUM_CLASSES):\n",
        "    \"\"\"Plots the distribution of wrong predictions for each class.\"\"\"\n",
        "    class_counts_wrong = defaultdict(int)\n",
        "\n",
        "    for idx in wrong_indices:\n",
        "        true_label = all_labels[idx]\n",
        "        class_counts_wrong[true_label] += 1\n",
        "\n",
        "    class_labels = sorted(class_counts_wrong.keys())\n",
        "    counts = [class_counts_wrong[label] for label in class_labels]\n",
        "    colors = sns.color_palette(\"husl\", len(class_labels))\n",
        "\n",
        "    class_names = [f\"Class {label}\" for label in class_labels]\n",
        "\n",
        "    sns.set(style=\"whitegrid\")\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.barh(class_names, counts, color=colors)\n",
        "    plt.xlabel('Number of Wrong Predictions')\n",
        "    plt.ylabel('Crop Disease Classes')\n",
        "    plt.title('Distribution of Wrong Predictions for Each Class')\n",
        "\n",
        "    for i, (count, name) in enumerate(zip(counts, class_names)):\n",
        "        plt.text(count, i, str(count), ha='left', va='center')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-JLU6In10Tr"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    \"GloVe_GRU_BahdanauAttention\": GloVe_GRU_BahdanauAttention(embedding_matrix=embedding_matrix, hidden_dim=300, num_classes=NUM_CLASSES, num_layers=1, dropout_prob=0.9).to(device),\n",
        "    \"PubMedBERT_GRU_Attention\": PubMedBERT_GRU_Attention(BERT_DIM, HIDDEN_DIM,num_layers=1, dropout_prob=DROPOUT).to(device),\n",
        "}\n",
        "\n",
        "optimizers = {\n",
        "    \"GloVe_GRU_BahdanauAttention\": optim.RMSprop(models[\"GloVe_GRU_BahdanauAttention\"].parameters(), lr=9e-5, weight_decay = 1e-5),\n",
        "    \"PubMedBERT_GRU_Attention\": optim.Adam(models[\"PubMedBERT_GRU_Attention\"].parameters(), lr=9e-5, weight_decay = 1e-5),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTyJijoj10Tr"
      },
      "outputs": [],
      "source": [
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "loss_gap_ratio = 1.25\n",
        "ax_accuracy_gap = 5\n",
        "num_epochs = 7\n",
        "\n",
        "model_metrics = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\nTraining {model_name} model...\\n\")\n",
        "    print(model)\n",
        "    num_params = count_parameters(model)\n",
        "    print(f\"Total trainable parameters: {num_params}\")\n",
        "\n",
        "    reinitialize_weights(model)\n",
        "    optimizer = optimizers[model_name]\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
        "\n",
        "    if \"PubMedBERT\" in model_name:\n",
        "        train_dataset = PubMedBERTBinaryDataset(X_train.tolist(), y_train, tokenizer)\n",
        "        val_dataset = PubMedBERTBinaryDataset(X_val.tolist(), y_val, tokenizer)\n",
        "        test_dataset = PubMedBERTBinaryDataset(X_test.tolist(), y_test, tokenizer)\n",
        "    else:\n",
        "        train_dataset = TextDataset(X_train_tensor, y_train, raw_text_data=X_train)\n",
        "        val_dataset = TextDataset(X_val_tensor, y_val, raw_text_data=X_val)\n",
        "        test_dataset = TextDataset(X_test_tensor, y_test, raw_text_data=X_test)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    combined_dataset = ConcatDataset([train_dataset, val_dataset])\n",
        "    combined_loader = DataLoader(combined_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    wandb.init(\n",
        "        project='Multi-Class-Models-Train-Test-PubeMedBERT-Glove300d-Attention',\n",
        "        name=f\"{model_name}_Training\",\n",
        "        config={\n",
        "            'learning_rate': 9e-5,\n",
        "            'num_epochs': num_epochs,\n",
        "            'num_layers': 1\n",
        "        }\n",
        "    )\n",
        "\n",
        "    train_losses, test_losses = [], []\n",
        "    train_accuracies, test_accuracies = [], []\n",
        "    test_f1s, test_balanced_accs, test_recalls, test_precisions = [], [], [], []\n",
        "\n",
        "    saved_once = False\n",
        "    with tqdm(total=num_epochs, desc=f\"Training {model_name}\", unit=\"epoch\") as pbar:\n",
        "        for epoch in range(num_epochs):\n",
        "            start_time = time.time()\n",
        "\n",
        "            if \"PubMedBERT\" in model_name:\n",
        "                train_loss, train_acc = train_model(model, combined_loader, optimizer, loss_function, device)\n",
        "                test_loss, test_acc, test_f1, test_balanced_acc, test_recall, test_precision = test_model(\n",
        "                    model, test_loader, loss_function, device)\n",
        "            else:\n",
        "                train_loss, train_acc = train_epoch_glove(model, combined_loader, optimizer, loss_function, device)\n",
        "                test_loss, test_acc, test_f1, test_balanced_acc, test_recall, test_precision = test_epoch_glove(\n",
        "                    model, test_loader, loss_function, device)\n",
        "\n",
        "            train_losses.append(train_loss)\n",
        "            test_losses.append(test_loss)\n",
        "            train_accuracies.append(train_acc)\n",
        "            test_accuracies.append(test_acc)\n",
        "            test_f1s.append(test_f1)\n",
        "            test_balanced_accs.append(test_balanced_acc)\n",
        "            test_recalls.append(test_recall)\n",
        "            test_precisions.append(test_precision)\n",
        "\n",
        "            wandb.log({\n",
        "                \"train_loss\": train_loss,\n",
        "                \"test_loss\": test_loss,\n",
        "                \"train_acc\": train_acc,\n",
        "                \"test_acc\": test_acc,\n",
        "                \"test_f1\": test_f1,\n",
        "                \"test_balanced_acc\": test_balanced_acc,\n",
        "                \"test_recall\": test_recall,\n",
        "                \"test_precision\": test_precision\n",
        "            })\n",
        "\n",
        "            if (test_loss > train_loss * loss_gap_ratio or train_acc - test_acc > ax_accuracy_gap / 100) and not saved_once:\n",
        "                torch.save(model.state_dict(), f\"{model_name}_early_stop.pth\")\n",
        "                saved_once = True\n",
        "                break\n",
        "\n",
        "            if epoch == num_epochs - 1 and not saved_once:\n",
        "                torch.save(model.state_dict(), f\"{model_name}_final.pth\")\n",
        "\n",
        "            pbar.set_description(\n",
        "                f\"{model_name} Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, \"\n",
        "                f\"Train Acc: {train_acc:.2%}, Test Acc: {test_acc:.2%}, Test F1: {test_f1:.2%}, \"\n",
        "                f\"Test Balanced Acc: {test_balanced_acc:.2%}, Test Recall: {test_recall:.2%}, Test Precision: {test_precision:.2%}, \"\n",
        "                f\"Time: {(time.time() - start_time) / 60:.2f} min\"\n",
        "            )\n",
        "            pbar.update(1)\n",
        "\n",
        "        epoch_table = wandb.Table(columns=[\"Epoch\", \"Train Loss\", \"Test Loss\", \"Train Acc\", \"Test Acc\", \"F1\", \"Balanced Acc\", \"Recall\", \"Precision\"])\n",
        "        for epoch in range(len(train_losses)):\n",
        "            epoch_table.add_data(epoch + 1, train_losses[epoch], test_losses[epoch], train_accuracies[epoch],\n",
        "                                 test_accuracies[epoch], test_f1s[epoch], test_balanced_accs[epoch],\n",
        "                                 test_recalls[epoch], test_precisions[epoch])\n",
        "        wandb.log({f\"{model_name}_Metrics_Table\": epoch_table})\n",
        "\n",
        "        wandb.log({\n",
        "            'train_loss_over_epochs': wandb.plot.line_series(\n",
        "                xs=list(range(1, num_epochs+1)),\n",
        "                ys=[train_losses, test_losses],\n",
        "                keys=['Train Loss', 'Test Loss'],\n",
        "                title='Loss Over Epochs',\n",
        "                xname='Epoch'\n",
        "            ),\n",
        "            'train_acc_over_epochs': wandb.plot.line_series(\n",
        "                xs=list(range(1, num_epochs+1)),\n",
        "                ys=[train_accuracies, test_accuracies],\n",
        "                keys=['Train Accuracy', 'Test Accuracy'],\n",
        "                title='Accuracy Over Epochs',\n",
        "                xname='Epoch'\n",
        "            ),\n",
        "            'test_f1_over_epochs': wandb.plot.line_series(\n",
        "                xs=list(range(1, num_epochs+1)),\n",
        "                ys=[test_f1s],\n",
        "                keys=['Test F1 Score'],\n",
        "                title='Test F1 Score Over Epochs',\n",
        "                xname='Epoch'\n",
        "            )\n",
        "        })\n",
        "\n",
        "        model_metrics[model_name] = {\n",
        "            \"train_losses\": train_losses,\n",
        "            \"test_losses\": test_losses,\n",
        "            \"train_accuracies\": train_accuracies,\n",
        "            \"test_accuracies\": test_accuracies,\n",
        "            \"test_f1s\": test_f1s,\n",
        "            \"test_balanced_accs\": test_balanced_accs,\n",
        "            \"test_recalls\": test_recalls,\n",
        "            \"test_precisions\": test_precisions\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntg70wrx10Tr"
      },
      "outputs": [],
      "source": [
        "summary_metrics = {\n",
        "    \"Model\": [],\n",
        "    \"F1 Score\": [],\n",
        "    \"Balanced Accuracy\": [],\n",
        "    \"Recall\": [],\n",
        "    \"Precision\": []\n",
        "}\n",
        "\n",
        "for model_name, metrics in model_metrics.items():\n",
        "    summary_metrics[\"Model\"].append(model_name)\n",
        "    summary_metrics[\"F1 Score\"].append(max(metrics[\"test_f1s\"]))\n",
        "    summary_metrics[\"Balanced Accuracy\"].append(max(metrics[\"test_balanced_accs\"]))\n",
        "    summary_metrics[\"Recall\"].append(max(metrics[\"test_recalls\"]))\n",
        "    summary_metrics[\"Precision\"].append(max(metrics[\"test_precisions\"]))\n",
        "\n",
        "df_summary = pd.DataFrame(summary_metrics)\n",
        "df_melted = df_summary.melt(id_vars=\"Model\", var_name=\"Metric\", value_name=\"Score\")\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "models = df_summary[\"Model\"].tolist()\n",
        "palette = sns.color_palette(\"Set2\", len(models))\n",
        "\n",
        "for i, metric in enumerate(df_melted[\"Metric\"].unique()):\n",
        "    data = df_melted[df_melted[\"Metric\"] == metric]\n",
        "    max_score = data[\"Score\"].max()\n",
        "\n",
        "    for j, (index, row) in enumerate(data.iterrows()):\n",
        "        color = \"crimson\" if row[\"Score\"] == max_score else palette[models.index(row[\"Model\"])]\n",
        "        bar = ax.bar(\n",
        "            x=i - 0.3 + j * (0.6 / len(models)),\n",
        "            height=row[\"Score\"],\n",
        "            width=0.6 / len(models),\n",
        "            color=color,\n",
        "            label=row[\"Model\"] if i == 0 else \"\",\n",
        "        )\n",
        "        ax.text(\n",
        "            x=bar[0].get_x() + bar[0].get_width() / 2,\n",
        "            y=row[\"Score\"] + 0.015,\n",
        "            s=f\"{row['Score']:.2f}\",\n",
        "            ha='center',\n",
        "            va='bottom',\n",
        "            fontsize=9,\n",
        "            color='black',\n",
        "            fontweight='bold' if row[\"Score\"] == max_score else 'normal'\n",
        "        )\n",
        "\n",
        "ax.set_xticks(range(len(df_melted[\"Metric\"].unique())))\n",
        "ax.set_xticklabels(df_melted[\"Metric\"].unique())\n",
        "ax.set_ylim(0, 1.05)\n",
        "ax.set_ylabel(\"Score\")\n",
        "ax.set_title(\"Best Performance per Model (using glove 300d as embeddings)\")\n",
        "ax.grid(True, axis='y')\n",
        "\n",
        "handles, labels = ax.get_legend_handles_labels()\n",
        "by_label = dict(zip(labels, handles))\n",
        "ax.legend(by_label.values(), by_label.keys(), title=\"Model\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"best_model_performance_comparison_all_values_glove300d.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZHJ3J1oB14U"
      },
      "source": [
        "---\n",
        "The PubMedBERT-based model with Bidirectional GRU and Bahdanau Attention consistently outperforms the GloVe-based model with Bidirectional GRU and Bahdanau Attention across all key metrics, though by a small margin of 0.01.\n",
        "\n",
        "This performance gain, while subtle, demonstrates that contextual embeddings like PubMedBERT provide a more nuanced and contextual understanding of biomedical text compared to traditional word embeddings like GloVe.\n",
        "\n",
        "Furthermore, the consistency across F1 Score, Precision, Recall, and Balanced Accuracy suggests that the PubMedBERT-based model with Bidirectional GRU and Bahdanau Attention delivers more stable and generalizable predictions, which is especially valuable when dealing with class-imbalanced biomedical datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvPSYJM110Ts"
      },
      "outputs": [],
      "source": [
        "with open(\"model_metrics.pkl\", \"wb\") as f:\n",
        "    pickle.dump(model_metrics, f)\n",
        "\n",
        "with open(\"model_metrics.pkl\", \"rb\") as f:\n",
        "    model_metrics = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmF51zVs10Ts"
      },
      "outputs": [],
      "source": [
        "test_dataset_pubMed = PubMedBERTBinaryDataset(X_test.tolist(), y_test, tokenizer)\n",
        "test_dataset_glove = TextDataset(X_test_tensor, y_test, raw_text_data=X_test)\n",
        "\n",
        "test_loader_pubMed = DataLoader(test_dataset_pubMed, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader_glove = DataLoader(test_dataset_glove, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "model_glove = GloVe_GRU_BahdanauAttention(embedding_matrix=embedding_matrix, hidden_dim=300, num_classes=NUM_CLASSES, num_layers=1, dropout_prob=0.9).to(device)\n",
        "model_glove.load_state_dict(torch.load(\"/content/drive/MyDrive/GloVe_GRU_BahdanauAttention_final.pth\"))\n",
        "\n",
        "model_pubMedBert = PubMedBERT_GRU_Attention(BERT_DIM, HIDDEN_DIM,num_layers=1, dropout_prob=DROPOUT).to(device)\n",
        "model_pubMedBert.load_state_dict(torch.load(\"/content/drive/MyDrive/PubMedBERT_GRU_Attention_early_stop.pth\"))\n",
        "\n",
        "df_results_glove, df_correct_glove, df_wrong_glove, all_labels_glove, all_preds_glove = evaluate_and_analyze_glove(model_glove, test_loader_glove, device)\n",
        "df_results_pubMedBert,  df_wrong_pubMedBert,df_correct_pubMedBert, all_labels_pubMedBert, all_preds_pubMedBert= evaluate_and_analyze_pubMedBert(model_pubMedBert, test_loader_pubMed, device )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-djzOKC10Ts"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
        "\n",
        "plot_confusion_matrix(axes[0], all_labels_glove, all_preds_glove, NUM_CLASSES)\n",
        "axes[0].set_title(\"Glove (300d) + Bahdanau Attention - Model Confusion Matrix\")\n",
        "\n",
        "plot_confusion_matrix(axes[1], all_labels_pubMedBert, all_preds_pubMedBert, NUM_CLASSES)\n",
        "axes[1].set_title(\"PubMedBert + Bahdanau Attention - Model Confusion Matrix\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NsaKTynB36x"
      },
      "source": [
        "### Confusion Matrix Comparison Summary\n",
        "\n",
        "This section compares the performance of two models using confusion matrices:\n",
        "\n",
        "- **Model 1:** GloVe (300d) as word embeddings + Bidirectional GRU + Bahdanau Attention  \n",
        "- **Model 2:** PubMedBert as contextual embeddings + Bidirectional GRU + Bahdanau Attention\n",
        "\n",
        "---\n",
        "\n",
        "#### Key Observations\n",
        "\n",
        "- **Overall Accuracy:**\n",
        "  - The model using contextual embeddings (**PubMedBert**) outperforms the one using word embeddings (**GloVe**) in most classes, demonstrating better generalization and fewer misclassifications.\n",
        "\n",
        "- **Diagonal Strength (Correct Predictions):**\n",
        "  - **PubMedBert** shows higher or equal correct predictions in critical classes like **0, 5, and 8**.\n",
        "  - Both models perform nearly identically on **class 3** and exceptionally well on **class 6**, with minimal misclassifications.\n",
        "\n",
        "- **Common Misclassifications:**\n",
        "  - **GloVe-based model** exhibits higher confusion in **class 2** and **class 8**, misclassifying several samples into other classes.\n",
        "  - **PubMedBert-based model** also makes some misclassifications (notably between classes **0, 2, and 5**) but at a reduced rate.\n",
        "\n",
        "---\n",
        "\n",
        "#### Conclusion\n",
        "\n",
        "> **PubMedBert + Bidirectional GRU + Bahdanau Attention** demonstrates superior performance over the **GloVe-based bidirectional GRU model**, particularly in biomedical class predictions. It consistently shows **lower off-diagonal error rates**, making it more robust and reliable for downstream tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Er12Ov_R10Ts"
      },
      "outputs": [],
      "source": [
        "class_names_dict = {\n",
        "    0: 'Tuberculosis',\n",
        "    1: 'Cholera',\n",
        "    2: 'Leprosy',\n",
        "    3: 'Ebola',\n",
        "    4: 'Leukemia',\n",
        "    5: 'Asthma',\n",
        "    6: 'Parkinson',\n",
        "    7: 'Lupus',\n",
        "    8: 'Cystic Fibrosis'\n",
        "}\n",
        "\n",
        "wrong_df_pubMedBert = pd.DataFrame({'predictions': all_preds_pubMedBert, 'labels': all_labels_pubMedBert})\n",
        "wrong_df_pubMedBert['wrong'] = wrong_df_pubMedBert['predictions'] != wrong_df_pubMedBert['labels']\n",
        "\n",
        "wrong_df_glove = pd.DataFrame({'predictions': all_preds_glove, 'labels': all_labels_glove})\n",
        "wrong_df_glove['wrong'] = wrong_df_glove['predictions'] != wrong_df_glove['labels']\n",
        "\n",
        "def get_wrong_counts(df):\n",
        "    wrong_class_counts = defaultdict(int)\n",
        "    for _, row in df.iterrows():\n",
        "        if row['wrong']:\n",
        "            wrong_class_counts[row['predictions']] += 1\n",
        "    wrong_class_labels = sorted(wrong_class_counts.keys())\n",
        "    wrong_counts = [wrong_class_counts[label] for label in wrong_class_labels]\n",
        "    return wrong_class_labels, wrong_counts\n",
        "\n",
        "wrong_class_labels_pubMedBert, wrong_counts_pubMedBert = get_wrong_counts(wrong_df_pubMedBert)\n",
        "wrong_class_labels_glove, wrong_counts_glove = get_wrong_counts(wrong_df_glove)\n",
        "\n",
        "\n",
        "sns.set(style=\"whitegrid\", palette=\"muted\", font_scale=1.3)\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "wrong_colors_pubMedBert = sns.color_palette(\"husl\", len(wrong_class_labels_pubMedBert))\n",
        "class_names_pubMedBert = [class_names_dict[label] for label in wrong_class_labels_pubMedBert]\n",
        "axes[0].barh(class_names_pubMedBert, wrong_counts_pubMedBert, color=wrong_colors_pubMedBert)\n",
        "axes[0].set_xlabel('Number of Wrong Predictions (Test Set)', fontsize=14)\n",
        "axes[0].set_ylabel('Disease Classes', fontsize=14)\n",
        "axes[0].set_title('PubMedBert: Distribution of Wrong Predictions', fontsize=16)\n",
        "for i, (count, name) in enumerate(zip(wrong_counts_pubMedBert, class_names_pubMedBert)):\n",
        "    axes[0].text(count, i, str(count), ha='left', va='center', fontsize=12)\n",
        "\n",
        "wrong_colors_glove = sns.color_palette(\"husl\", len(wrong_class_labels_glove))\n",
        "class_names_glove = [class_names_dict[label] for label in wrong_class_labels_glove]\n",
        "axes[1].barh(class_names_glove, wrong_counts_glove, color=wrong_colors_glove)\n",
        "axes[1].set_xlabel('Number of Wrong Predictions (Test Set)', fontsize=14)\n",
        "axes[1].set_ylabel('Disease Classes', fontsize=14)\n",
        "axes[1].set_title('Glove: Distribution of Wrong Predictions', fontsize=16)\n",
        "for i, (count, name) in enumerate(zip(wrong_counts_glove, class_names_glove)):\n",
        "    axes[1].text(count, i, str(count), ha='left', va='center', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2Rp8abuB60-"
      },
      "source": [
        "---\n",
        "\n",
        "**Summary**\n",
        "\n",
        "\n",
        "Using PubMedBert enables to achieve lower misclassification rates in 5 out of 9 disease classes, especially for:\n",
        "\n",
        "Leprosy: 45% fewer wrong predictions\n",
        "\n",
        "Cholera: 64% fewer wrong predictions\n",
        "\n",
        "Leukemia: 75% fewer wrong predictions\n",
        "\n",
        "Using GloVe enables to perform slightly better in Parkinson, Ebola, and Tuberculosis.\n",
        "\n",
        "Tuberculosis remains the most challenging class for both models, especially PubMedBert."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbX2Bd0kfh1D"
      },
      "source": [
        "Voici la table mise Ã  jour avec les meilleures valeurs de chaque colonne mises en **gras** :\n",
        "\n",
        "---\n",
        "\n",
        "# **Model Performance Comparison**\n",
        "\n",
        "| **Model**                               | **Input Type**        | **Accuracy** | **Balanced Accuracy** | **F1 Score** | **Recall** | **Precision** |\n",
        "|-----------------------------------------|-----------------------|--------------|-----------------------|--------------|------------|---------------|\n",
        "| **GRU**                                 | No embeddings          | 87.74%       | 88.00%                | 87.78%       | 87.74%     | 88.00%        |\n",
        "| **LSTM**                                | No embeddings          | 88.13%       | 88.46%                | 88.36%       | 88.13%     | 88.88%        |\n",
        "| **CNN + GRU**                           | No embeddings          | 86.77%       | 87.09%                | 87.11%       | 86.77%     | 88.35%        |\n",
        "| **CNN + LSTM**                          | No embeddings          | 88.13%       | 88.40%                | 88.36%       | 88.13%     | 89.34%        |\n",
        "| **GRU**                                 | GloVe (300d)           | **92.17%**   | **92.36%**            | **92.15%**   | **92.17%** | **92.21%**    |\n",
        "| **LSTM**                                | GloVe (300d)           | 88.34%       | 88.82%                | 88.41%       | 88.34%     | 89.07%        |\n",
        "| **CNN + GRU**                           | GloVe (300d)           | 89.70%       | 89.86%                | 89.65%       | 89.70%     | 89.74%        |\n",
        "| **CNN + LSTM**                          | GloVe (300d)           | 88.88%       | 89.13%                | 88.97%       | 88.88%     | 89.60%        |\n",
        "| **Bidirectional GRU + Bahdanau Attention** | **PubMedBERT**         | **92.00%**       | **92.28%**            | **92.01%**       | **92.00%**     | **92.06%**        |\n",
        "| **Bidirectional GRU + Bahdanau Attention** | GloVe (300d)           | **90.63%**       | **90.86%**                | **90.64%**       | **90.63%**     | **90.67%**        |\n",
        "\n",
        "---\n",
        "Given the imbalance in the dataset, we are now tackling this issue by implementing techniques such as SMOTE, weighted training, and ADASYN. We will evaluate their impact by measuring improvements in model performance and the balance of the data distribution."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}